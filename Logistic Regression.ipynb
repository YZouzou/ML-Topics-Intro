{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "This notebook contains an implementation of binary logistic regression on the famous Iris dataset. Logistic regression using gradient descent and Newton's method is implemented. An L2 regularizer is added too.\n",
    "\n",
    "[Check my Github repository for similar introductory notebooks](https://github.com/YZouzou/ML-Topics-Intro)\n",
    "\n",
    "[Check Prof. Nando de Freitas slides here](https://www.cs.ubc.ca/~nando/340-2012/lectures/l21.pdf)\n",
    "\n",
    "Logistic regression is a classification that uses the **logistic function** to return class probabilities between 0 and 1.The output of the logistic regression model represent the probability of the given input to be of a certain class.\n",
    "\n",
    "Sigmoid or logistic function:\n",
    "$$ sigm(x) = \\frac{1}{1 + e^{-x}} = \\frac{e^{x}}{1 + e^{x}} $$\n",
    "This function returns a value between 0 and 1 for any input x.\n",
    "\n",
    "Similar to linear regression, an input feature vector ($x$) is multiplied by a parameter vector ($\\theta$) to predict the target. However, in logistic regression, this result is put in the sigmoid function to get the final prediction. Using the sigmoid function ensures that the prediction can be perceived as a probability, without the need to introduce complicated normalizers and constraints (ex: $ \\sum \\theta_j = 1$).\n",
    "\n",
    "Binary logistic regression likelihood:\n",
    "$$ \\prod_{i=1}^{n} \\pi_i^{y_i} \\cdot (1 - \\pi_i)^{1-y_i} $$\n",
    "Where\n",
    "* $\\pi_i$ is the sigmoid of the prediction, i.e. $\\frac{1}{1+e^{-x_i^T\\theta}}$\n",
    "* $y_i$ is the target value (1 or 0 in the binary case)\n",
    "\n",
    "Maximizing the likelihood would be equivalent to minimizing the negative log of the likelihood. This optimization problem cannot be solved directly, as is the case with linear regression, and therefore gradient descent method is used.\n",
    "\n",
    "Gradient of the negative log likelihood:\n",
    "$$ g = \\sum_{i=1}^n x_i^T (\\pi_i - y_i) = X^T (\\pi - y) $$\n",
    "\n",
    "Where:\n",
    "* $x_i$ of size ($d \\cdot 1$)\n",
    "* $X$ of size ($n \\cdot d$)\n",
    "* $y, \\pi$ of size ($n \\cdot 1$)\n",
    "\n",
    "Hessian matrix of the negative log likelihood:\n",
    "$$ H = \\sum_{i=1}^n \\pi_i (1 - \\pi_i) x_i x_i^T = X^T S X $$\n",
    "\n",
    "Where\n",
    "* $S$ is $diag \\left( \\pi_1 (1 - \\pi_1), \\pi_2 (1 - \\pi_2), ... \\pi_n (1 - \\pi_n) \\right) $ of size ($n \\cdot n$)\n",
    "\n",
    "Using the gradient descent function with a Hessian matrix (Newton's method) we get:\n",
    "\n",
    "\\begin{align*}\n",
    "\\theta_{k+1} &= \\theta_k - H_k^{-1} g_k\\\\\n",
    "             &= \\left( X^T S_k X \\right)^{-1} X^T \\left[ S_k X \\theta_k + y - \\pi_k \\right]\n",
    "\\end{align*}\n",
    "\n",
    "This optimization algorithm is known as **Iteratively Reweighted Least Squares (IRLS)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-8, 8, 100)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(x, y)\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['sl', 'sw', 'pl', 'pw', 'class']\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv', header = None)\n",
    "df.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sl   sw   pl   pw        class\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping one class to create a binary classification case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = df['class'] == df.loc[0, 'class']\n",
    "drop_idx = df[cond].index\n",
    "\n",
    "df = df.drop(index = drop_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 50 to 149\n",
      "Data columns (total 5 columns):\n",
      "sl       100 non-null float64\n",
      "sw       100 non-null float64\n",
      "pl       100 non-null float64\n",
      "pw       100 non-null float64\n",
      "class    100 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 4.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].map({'Iris-versicolor': 0, 'Iris-virginica': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling dataframe\n",
    "df = df.sample(n = df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Logistic Regression\n",
    "Here one feature will be used to predict the class in order to visualize results in a 2D graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Petal width (pw) has the highest correlation with the target variable (class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553855</td>\n",
       "      <td>0.828479</td>\n",
       "      <td>0.593709</td>\n",
       "      <td>0.494305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sw</td>\n",
       "      <td>0.553855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519802</td>\n",
       "      <td>0.566203</td>\n",
       "      <td>0.308080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pl</td>\n",
       "      <td>0.828479</td>\n",
       "      <td>0.519802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823348</td>\n",
       "      <td>0.786424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pw</td>\n",
       "      <td>0.593709</td>\n",
       "      <td>0.566203</td>\n",
       "      <td>0.823348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>class</td>\n",
       "      <td>0.494305</td>\n",
       "      <td>0.308080</td>\n",
       "      <td>0.786424</td>\n",
       "      <td>0.828129</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sl        sw        pl        pw     class\n",
       "sl     1.000000  0.553855  0.828479  0.593709  0.494305\n",
       "sw     0.553855  1.000000  0.519802  0.566203  0.308080\n",
       "pl     0.828479  0.519802  1.000000  0.823348  0.786424\n",
       "pw     0.593709  0.566203  0.823348  1.000000  0.828129\n",
       "class  0.494305  0.308080  0.786424  0.828129  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pw</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pw  class\n",
       "128  2.1      1\n",
       "108  1.8      1\n",
       "55   1.3      0\n",
       "129  1.6      1\n",
       "90   1.2      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[['pw', 'class']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df1['pw'].to_numpy().reshape(-1, 1)\n",
    "X1 = StandardScaler().fit_transform(X1)\n",
    "\n",
    "# Adding a column with ones for the bias\n",
    "X1 = np.concatenate([np.ones(X1.shape), X1], axis = 1)\n",
    "\n",
    "y1 = df['class'].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points\n",
    "n = X1.shape[0]\n",
    "\n",
    "# Number of features\n",
    "d = X1.shape[1]\n",
    "\n",
    "theta = np.random.rand(d).reshape(-1, 1)\n",
    "prev_theta = np.zeros(d).reshape(-1, 1) + 1000\n",
    "\n",
    "tolerance = 0.0001\n",
    "i = 0\n",
    "\n",
    "while any(np.abs(theta - prev_theta) > tolerance):\n",
    "    prev_theta = theta.copy()\n",
    "\n",
    "    pi = sigmoid(X1 @ theta)\n",
    "    S = np.diagflat(pi*(1-pi))\n",
    "\n",
    "    theta = np.linalg.solve(X1.T @ S @ X1, X1.T @ (S@X1@theta + y1 - pi))\n",
    "    i += 1\n",
    "    if i>100:\n",
    "        break\n",
    "\n",
    "predictions = sigmoid(X1 @ theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(colors = ['limegreen', 'skyblue'])\n",
    "\n",
    "ss = ax.scatter(x = df['pw'], y = df['class'], c = df['class'], cmap = cmap)\n",
    "ax.plot(df['pw'], predictions, 'kx', label = 'Logistic Reg. Predictions')\n",
    "\n",
    "ax.set_xlabel('Petal Width')\n",
    "ax.set_ylabel('Virginica Probability')\n",
    "\n",
    "cbar = fig.colorbar(ss, cmap = cmap, ticks = [0.25, 0.75], ax = ax, shrink = 0.6, label = 'Real Class')\n",
    "cbar.ax.set_yticklabels(['Versicolor', 'Virginica'])\n",
    "\n",
    "ax.set_yticks(np.linspace(0, 1, 11))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df.iloc[:, :-1])\n",
    "y = np.asarray(df['class'])\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_norm = scale.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a class for logistic regression fitting and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegression:\n",
    "    \n",
    "    def fit (self, X, y):\n",
    "        n = X.shape[0]\n",
    "        d = X.shape[1]\n",
    "        \n",
    "        theta = np.random.rand(d).reshape(-1, 1)\n",
    "        prev_theta = np.zeros(d).reshape(-1, 1) + 1000\n",
    "        \n",
    "        y = y.reshape(-1, 1)\n",
    "        \n",
    "        tolerance = 0.0001\n",
    "        i = 0\n",
    "        \n",
    "        while any(np.abs(theta - prev_theta) > tolerance):\n",
    "            prev_theta = theta.copy()\n",
    "            \n",
    "            pi = sigmoid(X @ theta)\n",
    "            S = np.diagflat(pi*(1-pi))\n",
    "    \n",
    "            theta = np.linalg.solve(X.T @ S @ X, X.T @ (S@X@theta + y - pi))\n",
    "            i += 1\n",
    "            if i>100:\n",
    "                break\n",
    "            \n",
    "        self.theta = theta\n",
    "    \n",
    "    def predict (self, X):\n",
    "        return np.around(sigmoid(X @ self.theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a column of ones to be multiplied by the bias (intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_myclass = np.concatenate((np.ones((X_norm.shape[0], 1)), X_norm), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison with scikit-learn LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model:\n",
      "Intercept:  -0.35439119051211215\n",
      "Coefficients:  [-1.62584216] [-2.21192859] [7.74567601] [7.72844057]\n",
      "\n",
      "Scikit-learn model:\n",
      "Intercept:  -0.35435519968998364\n",
      "Coefficients:  [-1.6258004  -2.21195472  7.74565206  7.7285987 ]\n"
     ]
    }
   ],
   "source": [
    "classifier = LogRegression()\n",
    "classifier.fit(X_myclass, y)\n",
    "\n",
    "print('My model:')\n",
    "print('Intercept: ', classifier.theta[0, 0])\n",
    "print('Coefficients: ', *classifier.theta[1:])\n",
    "\n",
    "log_class = LogisticRegression(solver = 'lbfgs', penalty = 'none')\n",
    "log_class.fit(X_norm, y)\n",
    "\n",
    "print('\\nScikit-learn model:')\n",
    "print('Intercept: ', *log_class.intercept_)\n",
    "print('Coefficients: ', *log_class.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization was done by adding a diagonal matrix of lmbda values **Why??**\n",
    "\n",
    "Results confrom with scikit learn `LogisicRegression(solver = 'liblinear')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression cost function (negative log likelihood) with an L2 regularizer:\n",
    "$$ \\prod_{i=1}^{n} \\pi_i^{y_i} \\cdot (1 - \\pi_i)^{1-y_i} $$\n",
    "\n",
    "$$ J(\\theta) = -\\sum^{n}_{i=1} y_i log \\pi_i -\\sum^{n}_{i=1} (1-y_i) log (1-\\pi_i) + \\frac{1}{2}\\lambda \\theta_i^2 $$\n",
    "\n",
    "Gradient:\n",
    "\n",
    "$$ \\frac{d(J(\\theta))}{d\\theta} = g = \\sum_{i=1}^n x_i^T (\\pi_i - y_i) + \\lambda \\theta_i= X^T (\\pi - y) + \\lambda I \\theta $$\n",
    "\n",
    "Hessian:\n",
    "\n",
    "$$ H = X^T S X + \\lambda I $$\n",
    "\n",
    "Where:\n",
    "* $I$ is the identity matrix of size ($d \\cdot d$)\n",
    "\n",
    "Gradient descent using Newton's method:\n",
    "\\begin{align*}\n",
    "\\theta_{k+1} &= \\theta_k - H^{-1}_k \\cdot g_k \\\\\n",
    "             &= \\theta_k - (X^T S X + \\lambda I)^{-1} (X^T (\\pi - y) + \\lambda \\theta)\n",
    "\\end{align*}\n",
    "\n",
    "Gradient descent using a constant learning rate (step size):\n",
    "$$ \\theta_{k+1} = \\theta_k - \\alpha \\cdot g_k $$\n",
    "\n",
    "[Check this Stackoverflow on scikit-learn solvers](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grad_descent_reg(X, y, alpha, lmbda, tolerance = 0.0001, print_steps = False, max_iter = 100):\n",
    "    \"\"\"\n",
    "    Compute L2 regularized logistic regression coefficients and intercept using gradient descent algorithm\n",
    "    Note: The intercept is affected by the regularization\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    alpha: Step size in the direction of the gradient descent\n",
    "    \n",
    "    lmbda: L2 regularization factor, where a large lmbda indicates higher regularization\n",
    "\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    \n",
    "    prev_theta = np.zeros(d).reshape(-1, 1) + 1000\n",
    "    theta = np.random.rand(d).reshape(-1, 1)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while any(np.abs(theta - prev_theta) > tolerance):\n",
    "        pi = sigmoid(X @ theta)\n",
    "        \n",
    "        prev_theta = theta.copy()\n",
    "        theta = theta - alpha * (X.T @ (pi - y) + lmbda*theta)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if print_steps is True:\n",
    "            print('Iteration: ', i)\n",
    "            print(np.sum((theta - prev_theta)**2))\n",
    "            \n",
    "        if i>max_iter:\n",
    "            print('Exceeded {} Iterations'.format(max_iter))\n",
    "            break\n",
    "            \n",
    "    return (theta, i)\n",
    "\n",
    "\n",
    "def _grad_descent(X, y, alpha, tolerance = 0.0001, print_steps = False, max_iter = False):\n",
    "    \"\"\"\n",
    "    Compute logistic regression coefficients and intercept using gradient descent algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    alpha: Step size in the direction of the gradient descent\n",
    "\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    \n",
    "    prev_theta = np.zeros(d).reshape(-1, 1) + 1000\n",
    "    theta = np.random.rand(d).reshape(-1, 1)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while any(np.abs(theta - prev_theta) > tolerance):\n",
    "        \n",
    "        pi = sigmoid(X @ theta)\n",
    "        \n",
    "        prev_theta = theta.copy()\n",
    "        theta = theta - alpha * X.T @ (pi - y)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if print_steps is True:\n",
    "            print('Iteration: ', i)\n",
    "            print(np.sum((theta - prev_theta)**2))\n",
    "            \n",
    "        if i>max_iter:\n",
    "            print('Exceeded {} Iterations'.format(max_iter))\n",
    "            break\n",
    "            \n",
    "    return (theta, i)\n",
    "\n",
    "  \n",
    "def _newton_reg(X, y, lmbda, tolerance = 0.0001, print_steps = False, max_iter = False):\n",
    "    \"\"\"\n",
    "    Compute L2 regularized logistic regression coefficients and intercept using Newton's method\n",
    "    Note: The intercept is affected by the regularization\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    lmbda: L2 regularization factor, where a large lmbda indicates higher regularization\n",
    "\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    \n",
    "    prev_theta = np.zeros(d).reshape(-1, 1) + 1000\n",
    "    theta = np.random.rand(d).reshape(-1, 1)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while any(np.abs(theta - prev_theta) > tolerance):\n",
    "        pi = sigmoid(X @ theta)\n",
    "        S = np.diagflat(pi*(1-pi))\n",
    "        \n",
    "        prev_theta = theta.copy()\n",
    "        dtheta = - np.linalg.inv(X.T @ S @ X + lmbda*np.eye(d)) @ (X.T @ (pi - y) + lmbda*theta)\n",
    "        theta = theta + dtheta\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if print_steps is True:\n",
    "            print('Iteration: ', i)\n",
    "            print(np.sum((theta - prev_theta)**2))\n",
    "            \n",
    "        if i>max_iter:\n",
    "            print('Exceeded {} Iterations'.format(max_iter))\n",
    "            break\n",
    "            \n",
    "    return (theta, i)\n",
    "\n",
    "def _newton(X, y, tolerance = 0.0001, print_steps = False, max_iter = False):\n",
    "    \"\"\"\n",
    "    Compute logistic regression coefficients and intercept using Newton's method\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    \n",
    "    prev_theta = np.zeros(d).reshape(-1, 1) + 1000\n",
    "    theta = np.random.rand(d).reshape(-1, 1)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while any(np.abs(theta - prev_theta) > tolerance):\n",
    "        pi = sigmoid(X @ theta)\n",
    "        S = np.diagflat(pi*(1-pi))\n",
    "        \n",
    "        prev_theta = theta.copy()\n",
    "        theta = np.linalg.solve(X.T @ S @ X, X.T @ (S@X@theta + y - pi))\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if print_steps is True:\n",
    "            print('Iteration: ', i)\n",
    "            print(np.sum((theta - prev_theta)**2))\n",
    "            \n",
    "        if i>max_iter:\n",
    "            print('Exceeded {} Iterations'.format(max_iter))\n",
    "            break\n",
    "            \n",
    "    return (theta, i)\n",
    "\n",
    "\n",
    "class LogRegression:\n",
    "    '''\n",
    "    Apply logistic regression on data with a binary target\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    lmbda: Regularization factor, the larger lmbda is the more regularized the model is\n",
    "    \n",
    "    alpha: Learning rate if newton_method is set to False\n",
    "    \n",
    "    regularizer: Boolean to determine whether to include an L2 regularizer or not\n",
    "    \n",
    "    newton_method: Boolean to determine whether to use newton's method (hessian matrix instead of learning rate)\n",
    "    \n",
    "    print_steps: Boolean to determine whether to print the variation\n",
    "                 between two following iterations of the coefficient vector.\n",
    "                 The variation is computed as the sum of squared differences.\n",
    "    '''\n",
    "    def __init__ (self, lmbda = 1, alpha = 0.01, regularizer = False, newton_method = False, print_steps = False):\n",
    "        self.lmbda = lmbda\n",
    "        self.alpha = alpha\n",
    "        self.regularizer = regularizer\n",
    "        self.newton_method = newton_method\n",
    "        self.print_steps = print_steps\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \n",
    "        y = y.reshape(-1, 1)\n",
    "        \n",
    "        max_iter = 1000\n",
    "        tolerance = 0.0001\n",
    "        i = 0\n",
    "        \n",
    "        if self.newton_method is True:\n",
    "            if self.regularizer is True:\n",
    "                self.theta, self.n_iter = _newton_reg(X, y,\n",
    "                                                      lmbda = self.lmbda,\n",
    "                                                      tolerance = tolerance,\n",
    "                                                      print_steps = self.print_steps,\n",
    "                                                      max_iter = max_iter)\n",
    "            else:\n",
    "                self.theta, self.n_iter = _newton(X, y,\n",
    "                                                      tolerance = tolerance,\n",
    "                                                      print_steps = self.print_steps,\n",
    "                                                      max_iter = max_iter)\n",
    "        else:\n",
    "            if self.regularizer is True:\n",
    "                self.theta, self.n_iter = _grad_descent_reg(X, y,\n",
    "                                                            alpha = self.alpha,\n",
    "                                                            lmbda = self.lmbda,\n",
    "                                                            tolerance = tolerance,\n",
    "                                                            print_steps = self.print_steps,\n",
    "                                                            max_iter = max_iter)\n",
    "            else:\n",
    "                self.theta, self.n_iter = _grad_descent(X, y,\n",
    "                                                            alpha = self.alpha,\n",
    "                                                            tolerance = tolerance,\n",
    "                                                            print_steps = self.print_steps,\n",
    "                                                            max_iter = max_iter)\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.around(sigmoid(X @ self.theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_myclass = np.concatenate((np.ones((X_norm.shape[0], 1)), X_norm), axis = 1)\n",
    "# X_myclass = np.concatenate((np.ones((X_norm.shape[0], 1)), X), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison with scikit-learn LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model:\n",
      "Number of iterations:  6\n",
      "Intercept:  0.070192698385558\n",
      "Coefficients:  [-0.1070882] [-0.43694553] [1.7362964] [1.9339381]\n",
      "Score:  0.96\n",
      "\n",
      "Scikit-learn model:\n",
      "Number of iterations:  6\n",
      "Intercept:  0.07018142268211375\n",
      "Coefficients:  [-0.10710097 -0.43696694  1.73626425  1.93396372]\n",
      "Score:  0.96\n"
     ]
    }
   ],
   "source": [
    "# INPUT\n",
    "\n",
    "# Regularization factor\n",
    "lmbda = 2\n",
    "\n",
    "# Inverse of regularization factor (for Scikit-learn model)\n",
    "C = 1/lmbda\n",
    "\n",
    "# Step size for steepest descent\n",
    "alpha = 0.08\n",
    "\n",
    "regularizer = True\n",
    "newton_method = True\n",
    "print_steps = False\n",
    "\n",
    "solver = 'liblinear'\n",
    "\n",
    "if regularizer is True:\n",
    "    penalty = 'l2'\n",
    "else:\n",
    "    solver = 'newton-cg'\n",
    "    penalty = 'none'\n",
    "\n",
    "\n",
    "classifier = LogRegression(lmbda = lmbda, alpha = alpha,\n",
    "                           regularizer = regularizer, newton_method = newton_method, print_steps = print_steps)\n",
    "classifier.fit(X_myclass, y)\n",
    "\n",
    "y_hat = classifier.predict(X_myclass)\n",
    "score = (y_hat.flatten() == y).sum() / y.shape[0]\n",
    "\n",
    "print('My model:')\n",
    "print('Number of iterations: ', classifier.n_iter)\n",
    "print('Intercept: ', classifier.theta[0, 0])\n",
    "print('Coefficients: ', *classifier.theta[1:])\n",
    "print('Score: ', score)\n",
    "\n",
    "log_class = LogisticRegression(solver = solver, penalty = penalty, C = C)\n",
    "log_class.fit(X_norm, y)\n",
    "y_hat = log_class.predict(X_norm)\n",
    "score = (y_hat.flatten() == y).sum() / y.shape[0]\n",
    "\n",
    "print('\\nScikit-learn model:')\n",
    "print('Number of iterations: ', log_class.n_iter_[0])\n",
    "print('Intercept: ', *log_class.intercept_)\n",
    "print('Coefficients: ', *log_class.coef_)\n",
    "print('Score: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "* Search about the effect of data normalization on logisitic regression\n",
    "* Check if the scikit-learn LogisticRegression model normalizes data\n",
    "* Apply line search and create a plot to show convergance path\n",
    "* Apply a multi-class logistic regression model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
